{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z0AlxKmQ1z3j"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers[sentencepiece] sacrebleu -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1g3LHfx2U6f",
        "outputId": "e3840ac2-3094-42d0-ab56-d2c3946a698c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)  # Restart the runtime\n"
      ],
      "metadata": {
        "id": "OXVJ6UiZ7l7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "print(\"Datasets library version:\", datasets.__version__)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv2VjoZs7r_0",
        "outputId": "6dc01cd7-2d84-4b77-a442-69f05fbb04b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets library version: 3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ideally, you should group imports from the same library like this:\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "import transformers\n",
        "from datasets import load_dataset\n",
        "from transformers import (AdamWeightDecay, AutoTokenizer, DataCollatorForSeq2Seq,\n",
        "                          TFAutoModelForSeq2SeqLM)"
      ],
      "metadata": {
        "id": "4m9vM-Yl14yp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"Helsinki-NLP/opus-mt-en-hi\""
      ],
      "metadata": {
        "id": "zG4bRD6G140-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets = load_dataset(\"cfilt/iitb-english-hindi\")"
      ],
      "metadata": {
        "id": "7WIYOiAc143k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f49eeb55-c30b-4fac-b224-626238581d65"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXCZAy8J1450",
        "outputId": "2cd8a60e-035d-4e7d-f750-ba60dbac3f9a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 1659083\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 520\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 2507\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets['train'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4dJ2WqD147_",
        "outputId": "4e2955fb-96e6-413a-fe5a-7d707e815c3c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'translation': {'en': 'Accerciser Accessibility Explorer',\n",
              "  'hi': 'एक्सेर्साइसर पहुंचनीयता अन्वेषक'}}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocessing on dataset"
      ],
      "metadata": {
        "id": "qhun9PPm2rkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NplQAEvS14-W",
        "outputId": "09148f12-919f-4fbc-b7a7-df9822677ac5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(\"hey , lets go\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWoO4ayF15AW",
        "outputId": "cc1d8dbe-2bae-4562-db13-abc698c95384"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [74, 667, 44, 2, 446, 16, 411, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer([\"Hello, this is a introduction.\", \"This is another sintroduction.\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqn9euOP15CL",
        "outputId": "876d7946-23b6-47b8-84d0-492d24b0104e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[12110, 2, 90, 23, 19, 19394, 3, 0], [239, 23, 414, 946, 9765, 10790, 18057, 3, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tokenizer.as_target_tokenizer():\n",
        "    print(tokenizer([\"एक्सेर्साइसर पहुंचनीयता अन्वेषक\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nvy0du2G15Eh",
        "outputId": "0d7db168-9373-482e-d1fb-e7bf625ed973"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[26618, 16155, 346, 33383, 0]], 'attention_mask': [[1, 1, 1, 1, 1]]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3953: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = 1000\n",
        "max_target_length = 1000\n",
        "\n",
        "source_lang = \"en\"\n",
        "target_lang = \"hi\"\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [ex[source_lang] for ex in examples[\"translation\"]]\n",
        "    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "Qeyc3_qp15GJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_function(raw_datasets[\"train\"][:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3bLyAvT15Ia",
        "outputId": "aaf8a8dc-9f60-4b93-f375-98b0add19ce9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[3872, 85, 2501, 132, 15441, 36398, 0], [32643, 28541, 36253, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1]], 'labels': [[63, 2025, 18, 16155, 346, 20311, 24, 2279, 679, 0], [26618, 16155, 346, 33383, 0]]}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "td4SclLO15KP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RYyapJy15Mb",
        "outputId": "b08c418a-54b5-41e9-92c6-d1ad1aecf498"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-hi.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "learning_rate = 2e-5\n",
        "weight_decay = 0.01\n",
        "num_train_epochs = 85"
      ],
      "metadata": {
        "id": "uLypoSjX5OUg"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")"
      ],
      "metadata": {
        "id": "fHegbtnE5OWw"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\", pad_to_multiple_of=128)"
      ],
      "metadata": {
        "id": "DYZsbD715b5T"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzGL3TRR6MDI",
        "outputId": "a8283c1b-b9ac-4829-de4e-b71b33bcbcd0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "train_dataset = model.prepare_tf_dataset(\n",
        "    tokenized_datasets[\"test\"],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        ")"
      ],
      "metadata": {
        "id": "xJvmDL-M5b7n"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset = model.prepare_tf_dataset(\n",
        "    tokenized_datasets[\"validation\"],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=data_collator,\n",
        ")"
      ],
      "metadata": {
        "id": "tS-LqwvW5b-D"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_dataset = model.prepare_tf_dataset(\n",
        "    tokenized_datasets[\"validation\"],\n",
        "    batch_size=8,\n",
        "    shuffle=False,\n",
        "    collate_fn=generation_data_collator,\n",
        ")"
      ],
      "metadata": {
        "id": "z0ZfgMwd8KL8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamWeightDecay(learning_rate=learning_rate, weight_decay_rate=weight_decay)\n",
        "model.compile(optimizer=optimizer)"
      ],
      "metadata": {
        "id": "GxFk0DH58KRi"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, validation_data=validation_dataset, epochs=85)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SObppH88KhG",
        "outputId": "6955bcbe-f2fe-41e8-ae20-82c827e5d5ed"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/85\n",
            "78/78 [==============================] - 71s 608ms/step - loss: 0.1509 - val_loss: 4.6938\n",
            "Epoch 2/85\n",
            "78/78 [==============================] - 41s 527ms/step - loss: 0.1414 - val_loss: 4.7083\n",
            "Epoch 3/85\n",
            "78/78 [==============================] - 42s 543ms/step - loss: 0.1329 - val_loss: 4.7254\n",
            "Epoch 4/85\n",
            "78/78 [==============================] - 43s 554ms/step - loss: 0.1268 - val_loss: 4.7565\n",
            "Epoch 5/85\n",
            "78/78 [==============================] - 43s 557ms/step - loss: 0.1209 - val_loss: 4.7771\n",
            "Epoch 6/85\n",
            "78/78 [==============================] - 44s 566ms/step - loss: 0.1153 - val_loss: 4.7616\n",
            "Epoch 7/85\n",
            "78/78 [==============================] - 45s 573ms/step - loss: 0.1058 - val_loss: 4.7911\n",
            "Epoch 8/85\n",
            "78/78 [==============================] - 42s 541ms/step - loss: 0.1002 - val_loss: 4.7931\n",
            "Epoch 9/85\n",
            "78/78 [==============================] - 43s 555ms/step - loss: 0.0957 - val_loss: 4.8316\n",
            "Epoch 10/85\n",
            "78/78 [==============================] - 44s 563ms/step - loss: 0.0908 - val_loss: 4.8355\n",
            "Epoch 11/85\n",
            "78/78 [==============================] - 43s 552ms/step - loss: 0.0872 - val_loss: 4.8424\n",
            "Epoch 12/85\n",
            "78/78 [==============================] - 43s 550ms/step - loss: 0.0834 - val_loss: 4.8544\n",
            "Epoch 13/85\n",
            "78/78 [==============================] - 44s 564ms/step - loss: 0.0783 - val_loss: 4.8721\n",
            "Epoch 14/85\n",
            "78/78 [==============================] - 44s 560ms/step - loss: 0.0741 - val_loss: 4.9018\n",
            "Epoch 15/85\n",
            "78/78 [==============================] - 43s 556ms/step - loss: 0.0717 - val_loss: 4.9159\n",
            "Epoch 16/85\n",
            "78/78 [==============================] - 43s 557ms/step - loss: 0.0683 - val_loss: 4.9313\n",
            "Epoch 17/85\n",
            "78/78 [==============================] - 43s 559ms/step - loss: 0.0647 - val_loss: 4.9255\n",
            "Epoch 18/85\n",
            "78/78 [==============================] - 44s 563ms/step - loss: 0.0627 - val_loss: 4.9610\n",
            "Epoch 19/85\n",
            "78/78 [==============================] - 44s 563ms/step - loss: 0.0589 - val_loss: 4.9665\n",
            "Epoch 20/85\n",
            "78/78 [==============================] - 44s 561ms/step - loss: 0.0567 - val_loss: 4.9764\n",
            "Epoch 21/85\n",
            "78/78 [==============================] - 43s 549ms/step - loss: 0.0544 - val_loss: 4.9669\n",
            "Epoch 22/85\n",
            "78/78 [==============================] - 45s 570ms/step - loss: 0.0542 - val_loss: 4.9895\n",
            "Epoch 23/85\n",
            "78/78 [==============================] - 44s 565ms/step - loss: 0.0510 - val_loss: 4.9660\n",
            "Epoch 24/85\n",
            "78/78 [==============================] - 44s 561ms/step - loss: 0.0482 - val_loss: 5.0087\n",
            "Epoch 25/85\n",
            "78/78 [==============================] - 44s 562ms/step - loss: 0.0463 - val_loss: 5.0133\n",
            "Epoch 26/85\n",
            "78/78 [==============================] - 43s 554ms/step - loss: 0.0453 - val_loss: 5.0258\n",
            "Epoch 27/85\n",
            "78/78 [==============================] - 43s 555ms/step - loss: 0.0430 - val_loss: 5.0291\n",
            "Epoch 28/85\n",
            "78/78 [==============================] - 44s 565ms/step - loss: 0.0434 - val_loss: 5.0382\n",
            "Epoch 29/85\n",
            "78/78 [==============================] - 44s 559ms/step - loss: 0.0401 - val_loss: 5.0403\n",
            "Epoch 30/85\n",
            "78/78 [==============================] - 43s 555ms/step - loss: 0.0390 - val_loss: 5.0714\n",
            "Epoch 31/85\n",
            "78/78 [==============================] - 44s 561ms/step - loss: 0.0370 - val_loss: 5.0587\n",
            "Epoch 32/85\n",
            "78/78 [==============================] - 43s 553ms/step - loss: 0.0355 - val_loss: 5.0858\n",
            "Epoch 33/85\n",
            "78/78 [==============================] - 44s 559ms/step - loss: 0.0354 - val_loss: 5.0891\n",
            "Epoch 34/85\n",
            "78/78 [==============================] - 44s 566ms/step - loss: 0.0344 - val_loss: 5.1015\n",
            "Epoch 35/85\n",
            "78/78 [==============================] - 44s 564ms/step - loss: 0.0324 - val_loss: 5.0946\n",
            "Epoch 36/85\n",
            "78/78 [==============================] - 44s 568ms/step - loss: 0.0310 - val_loss: 5.1092\n",
            "Epoch 37/85\n",
            "78/78 [==============================] - 44s 567ms/step - loss: 0.0305 - val_loss: 5.1170\n",
            "Epoch 38/85\n",
            "78/78 [==============================] - 44s 565ms/step - loss: 0.0300 - val_loss: 5.1043\n",
            "Epoch 39/85\n",
            "78/78 [==============================] - 44s 566ms/step - loss: 0.0290 - val_loss: 5.1284\n",
            "Epoch 40/85\n",
            "78/78 [==============================] - 44s 567ms/step - loss: 0.0276 - val_loss: 5.1381\n",
            "Epoch 41/85\n",
            "78/78 [==============================] - 44s 562ms/step - loss: 0.0271 - val_loss: 5.1378\n",
            "Epoch 42/85\n",
            "78/78 [==============================] - 43s 560ms/step - loss: 0.0266 - val_loss: 5.1573\n",
            "Epoch 43/85\n",
            "78/78 [==============================] - 44s 565ms/step - loss: 0.0258 - val_loss: 5.1489\n",
            "Epoch 44/85\n",
            "78/78 [==============================] - 43s 553ms/step - loss: 0.0240 - val_loss: 5.1638\n",
            "Epoch 45/85\n",
            "78/78 [==============================] - 44s 563ms/step - loss: 0.0246 - val_loss: 5.1601\n",
            "Epoch 46/85\n",
            "78/78 [==============================] - 44s 573ms/step - loss: 0.0231 - val_loss: 5.1608\n",
            "Epoch 47/85\n",
            "78/78 [==============================] - 44s 563ms/step - loss: 0.0230 - val_loss: 5.1776\n",
            "Epoch 48/85\n",
            "78/78 [==============================] - 43s 559ms/step - loss: 0.0222 - val_loss: 5.1742\n",
            "Epoch 49/85\n",
            "78/78 [==============================] - 43s 552ms/step - loss: 0.0216 - val_loss: 5.1781\n",
            "Epoch 50/85\n",
            "78/78 [==============================] - 44s 568ms/step - loss: 0.0208 - val_loss: 5.2050\n",
            "Epoch 51/85\n",
            "78/78 [==============================] - 44s 569ms/step - loss: 0.0200 - val_loss: 5.2137\n",
            "Epoch 52/85\n",
            "78/78 [==============================] - 44s 568ms/step - loss: 0.0191 - val_loss: 5.2031\n",
            "Epoch 53/85\n",
            "78/78 [==============================] - 43s 554ms/step - loss: 0.0184 - val_loss: 5.2172\n",
            "Epoch 54/85\n",
            "78/78 [==============================] - 44s 570ms/step - loss: 0.0183 - val_loss: 5.2086\n",
            "Epoch 55/85\n",
            "78/78 [==============================] - 44s 561ms/step - loss: 0.0184 - val_loss: 5.2212\n",
            "Epoch 56/85\n",
            "78/78 [==============================] - 43s 554ms/step - loss: 0.0183 - val_loss: 5.2527\n",
            "Epoch 57/85\n",
            "78/78 [==============================] - 43s 553ms/step - loss: 0.0178 - val_loss: 5.2626\n",
            "Epoch 58/85\n",
            "78/78 [==============================] - 44s 567ms/step - loss: 0.0178 - val_loss: 5.2429\n",
            "Epoch 59/85\n",
            "78/78 [==============================] - 43s 552ms/step - loss: 0.0173 - val_loss: 5.2594\n",
            "Epoch 60/85\n",
            "78/78 [==============================] - 44s 562ms/step - loss: 0.0166 - val_loss: 5.2496\n",
            "Epoch 61/85\n",
            "78/78 [==============================] - 44s 562ms/step - loss: 0.0172 - val_loss: 5.2743\n",
            "Epoch 62/85\n",
            "78/78 [==============================] - 44s 568ms/step - loss: 0.0174 - val_loss: 5.2743\n",
            "Epoch 63/85\n",
            "78/78 [==============================] - 44s 569ms/step - loss: 0.0166 - val_loss: 5.2974\n",
            "Epoch 64/85\n",
            "78/78 [==============================] - 44s 566ms/step - loss: 0.0160 - val_loss: 5.3066\n",
            "Epoch 65/85\n",
            "78/78 [==============================] - 44s 570ms/step - loss: 0.0157 - val_loss: 5.3071\n",
            "Epoch 66/85\n",
            "78/78 [==============================] - 43s 554ms/step - loss: 0.0146 - val_loss: 5.3129\n",
            "Epoch 67/85\n",
            "78/78 [==============================] - 44s 570ms/step - loss: 0.0148 - val_loss: 5.3202\n",
            "Epoch 68/85\n",
            "78/78 [==============================] - 45s 570ms/step - loss: 0.0142 - val_loss: 5.3054\n",
            "Epoch 69/85\n",
            "78/78 [==============================] - 44s 568ms/step - loss: 0.0143 - val_loss: 5.3234\n",
            "Epoch 70/85\n",
            "78/78 [==============================] - 44s 563ms/step - loss: 0.0153 - val_loss: 5.3409\n",
            "Epoch 71/85\n",
            "78/78 [==============================] - 43s 559ms/step - loss: 0.0139 - val_loss: 5.3513\n",
            "Epoch 72/85\n",
            "78/78 [==============================] - 44s 565ms/step - loss: 0.0141 - val_loss: 5.3434\n",
            "Epoch 73/85\n",
            "78/78 [==============================] - 44s 563ms/step - loss: 0.0129 - val_loss: 5.3470\n",
            "Epoch 74/85\n",
            "78/78 [==============================] - 43s 556ms/step - loss: 0.0139 - val_loss: 5.3578\n",
            "Epoch 75/85\n",
            "78/78 [==============================] - 44s 561ms/step - loss: 0.0128 - val_loss: 5.3373\n",
            "Epoch 76/85\n",
            "78/78 [==============================] - 45s 573ms/step - loss: 0.0129 - val_loss: 5.3769\n",
            "Epoch 77/85\n",
            "78/78 [==============================] - 44s 568ms/step - loss: 0.0120 - val_loss: 5.3899\n",
            "Epoch 78/85\n",
            "78/78 [==============================] - 44s 572ms/step - loss: 0.0128 - val_loss: 5.3644\n",
            "Epoch 79/85\n",
            "78/78 [==============================] - 44s 558ms/step - loss: 0.0122 - val_loss: 5.4107\n",
            "Epoch 80/85\n",
            "78/78 [==============================] - 44s 565ms/step - loss: 0.0118 - val_loss: 5.4083\n",
            "Epoch 81/85\n",
            "78/78 [==============================] - 44s 568ms/step - loss: 0.0113 - val_loss: 5.4311\n",
            "Epoch 82/85\n",
            "78/78 [==============================] - 44s 565ms/step - loss: 0.0117 - val_loss: 5.4177\n",
            "Epoch 83/85\n",
            "78/78 [==============================] - 44s 562ms/step - loss: 0.0121 - val_loss: 5.4089\n",
            "Epoch 84/85\n",
            "78/78 [==============================] - 45s 572ms/step - loss: 0.0108 - val_loss: 5.4198\n",
            "Epoch 85/85\n",
            "78/78 [==============================] - 43s 554ms/step - loss: 0.0108 - val_loss: 5.4303\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7f1c2c3633d0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"tf_model/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1S9kNzC8vvV",
        "outputId": "073ad551-c75e-4b08-9d27-eb41fe006664"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
            "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]]}\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(\"tf_model/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAT9DT3AXvvJ",
        "outputId": "ec22c487-602f-40be-f434-206dbf3d7d62"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tf_model/tokenizer_config.json',\n",
              " 'tf_model/special_tokens_map.json',\n",
              " 'tf_model/vocab.json',\n",
              " 'tf_model/source.spm',\n",
              " 'tf_model/target.spm',\n",
              " 'tf_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###testing"
      ],
      "metadata": {
        "id": "idQ5ycK4WGNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"tf_model/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN0Io2pMWE4b",
        "outputId": "53da4f28-aed8-4bd8-e90e-592ae704c706"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at tf_model/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text  = \"My name is Raj and I live in Delhi. I go to the park every morning and do yoga. I love reading books and listening to music. In my family, I have my parents and a younger sister. We all eat dinner together in the evening and share our day's experiences. I am very content with my life.\"\n",
        "\n",
        "tokenized = tokenizer([input_text], return_tensors='np')\n",
        "out = model.generate(**tokenized, max_length=1000)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTO_ZLeCWE62",
        "outputId": "e308d8ea-e1d3-465b-d628-a26e0a6f6027"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[61949   500   179  1686   130     5     9   104 36034    11  1081   743\n",
            "     40   104  2911 17429    11   273   254     9  3549 12433   260   273\n",
            "    254    40   104    63   823     6   116  5223     9  4985  2542     6\n",
            "     39   176   634   161   254    40     2   104    63   989    69 17254\n",
            "      9  1775  1699    18   116  2510 58196   161   254     2     9  4330\n",
            "     24    63   183     6  2538     6   116  4941   161   254    40     0]], shape=(1, 72), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tokenizer.as_target_tokenizer():\n",
        "    print(tokenizer.decode(out[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL2K2sLqWE88",
        "outputId": "8b115dd9-751f-4e8c-bce8-bc6e3ccb1b3e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "मेरा नाम राजी है और मैं दिल्ली में रहता हूं। मैं सुबह पार्क में जाता हूँ और गर्गा जाता हूँ। मैं अपने परिवार के साथ किताबें और संगीत सुनने के लिए बहुत प्यार करता हूँ।, मैं अपने माता-पिता और छोटे बहन को साथ मिलकर डिनर करता हूँ, और शाम का अपने दिन के अनुभव के साथ साझा करता हूँ।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save both model and tokenizer\n",
        "save_directory = \"english_hindi_translator\"\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWickcw8WE_D",
        "outputId": "5fc1efd2-e7ce-47c3-8c06-a89300ce3e54"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
            "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]]}\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('english_hindi_translator/tokenizer_config.json',\n",
              " 'english_hindi_translator/special_tokens_map.json',\n",
              " 'english_hindi_translator/vocab.json',\n",
              " 'english_hindi_translator/source.spm',\n",
              " 'english_hindi_translator/target.spm',\n",
              " 'english_hindi_translator/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In Colab, run:\n",
        "!zip -r english_hindi_translator.zip tf_model/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmnJ7MujX1hD",
        "outputId": "63d77d06-ea26-411b-f053-3a5a7d7ba758"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: tf_model/ (stored 0%)\n",
            "  adding: tf_model/target.spm (deflated 60%)\n",
            "  adding: tf_model/special_tokens_map.json (deflated 35%)\n",
            "  adding: tf_model/tokenizer_config.json (deflated 68%)\n",
            "  adding: tf_model/vocab.json (deflated 76%)\n",
            "  adding: tf_model/tf_model.h5 (deflated 7%)\n",
            "  adding: tf_model/config.json (deflated 61%)\n",
            "  adding: tf_model/generation_config.json (deflated 43%)\n",
            "  adding: tf_model/source.spm (deflated 51%)\n"
          ]
        }
      ]
    }
  ]
}